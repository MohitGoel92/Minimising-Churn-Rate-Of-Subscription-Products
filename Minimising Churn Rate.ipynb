{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimising Churn Rate Of Subscription Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subscription products often are the main source of revenue for companies across all industries, such as Netflix. These products may come in the form of a 'one size fits all' overcompassing subscription, or in multi-level memberships. Regardless of how they structure their memberships, or what industry they are in, companies usually try to minimise customer churn (a.k.a. subscription cancellations). To retain their customers, these companies are required to firstly identify behavioural patterns that act as a catalyst in disengagement with the product.\n",
    "\n",
    "- **Market:** The target audience is the entire company's subscription base. They are the ones the company wants to keep.\n",
    "\n",
    "- **Product:** The subscription products that customers are already enrolled in can provide value that users may not have imagined, or they may have forgotten.\n",
    "\n",
    "- **Goal:** The objective of this model is to predict which users are likely to churn, so that the company can focus on re-engaging these users with the product. These efforts can be notifications about the benefits of the product, especially focusing on features that are new or that the user has shown to value.\n",
    "<br><br>\n",
    "- In this case study we will be working for a fintech that provides a subscription product to its users, which allows them to manage their bank accounts (saving accounts, credit cards ... etc), provides them with personalised coupons, informs them of the latest low-APR loans available in the market, and educates them on the best available methods to save money (e.g. videos or saving money on taxes, free courses on financial health ... etc).\n",
    "- We are in charge of identifying users who are likely to cancel their subscription so that we can start building new features that they may be interested in. These features can increase the engagement and interest of our users towards the product.\n",
    "<br><br>\n",
    "- By subscribing to the membership, our customers have provided us with the data on their finances, as well as how they handle those finances through the product. We also have some demographic information we acquired from them during the sign-up process.\n",
    "- Financial data can often be unreliable and delayed. As a result, companies can build their marketing models using demographic data, and data related to finances handled through the product itself. Therefore, we will be restricting ourselves to only using that type of data. Furthermore, product-related data is more indicative of what new features we should be creating as a company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Care Of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This can be displayed graphically\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16,4)\n",
    "sns.heatmap(ds.isnull(), yticklabels = False, cbar = False, cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the visualisation above, we do not see any missing values for age. \n",
    "# We know there are missing values for age as the code above states 'True'for age. \n",
    "# From the code below, we observe only 4 missing values for age.\n",
    "# The above visualisation now makes sense as there is a large number of rows\n",
    "# (27,000) and as there are only 4 missing values, the line will be too thin to see.\n",
    "\n",
    "ds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of setting the blank columns of age to the average age, we will simply remove these rows.\n",
    "# The code below will return the dataset except any rows where the 'age' column had any blanks.\n",
    "\n",
    "ds = ds[pd.notnull(ds['age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe 26,996 rows as opposed to 27,000 rows, this being a result of removing the rows where \n",
    "# the age column was blank.\n",
    "\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the columns 'credit_score' and 'rewards_earned' contain a lot of blanks, we will remove these columns.\n",
    "# Note: These columns have been removed from our model and analysis.\n",
    "\n",
    "ds = ds.drop(columns = ['credit_score', 'rewards_earned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â We observe 29 columns, 2 less from the original 31.\n",
    "\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds.housing == 'O'].churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds.churn == 0].housing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ds.drop(columns = ['user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ds2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Histograms of Columns', fontsize = 20)\n",
    "for i in column_names:\n",
    "    plt.title(i)\n",
    "    plt.hist(ds2[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pie Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We will be making Pie Charts for the binary variables. This is because, if the binary variables are disproportionate (i.e. 99% are 0 and only 1% is 1), and the response variable for the disproportionate binary variable has a majority 0 or 1 as a response. Regardless of the other variables, that particular binary variable will have a greater influence on the response variable, resulting in the predicted response being highly dependent/correlated on that binary variable. We do not wish there to be a higher than desired dependence on any variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart for the Churn\n",
    "\n",
    "plt.suptitle('Churned Pie Chart', fontsize = 20)\n",
    "plt.pie([ds[ds['churn'] == 0]['churn'].count(), ds[ds['churn'] == 1]['churn'].count()],\n",
    "            labels = ['0','1'], colors = ['r','g'], startangle = 90, autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wish to only visualise Pie Charts for the binary variables.\n",
    "\n",
    "ds2 = ds[['is_referred', 'app_downloaded',\n",
    "          'web_user', 'app_web_user', 'ios_user',\n",
    "          'android_user','waiting_4_loan', 'cancelled_loan',\n",
    "          'received_loan', 'rejected_loan', \n",
    "          'left_for_two_month_plus', 'left_for_one_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ds2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2[ds2['is_referred'] == 0]['is_referred'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2[ds2['is_referred'] == 1]['is_referred'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe the following columns being highly disproportionate: \n",
    "# app_downloaded, waiting_4_loan, cancelled_loan, \n",
    "# received_loan, rejected_loan, left_for_one_month. \n",
    "\n",
    "plt.suptitle('Pie Chart Distribution', fontsize = 20)\n",
    "for i in columns:\n",
    "    plt.title(i)\n",
    "    plt.pie([ds2[ds2[i] == 0][i].count(), ds2[ds2[i] == 1][i].count()],\n",
    "            labels = ['0','1'], colors = ['r','g'], startangle = 90, autopct='%.1f%%')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â We will be observing the value counts of the above mentioned columns to check if either\n",
    "# binary value of 0 or 1 has a very high/low proportion of the churn. If it does, we may\n",
    "# decide to skip that column due to high correlation or something being suspicious.\n",
    "\n",
    "print(ds[ds.app_downloaded == 0].churn.value_counts())\n",
    "print(ds[ds.app_downloaded == 1].churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[ds.waiting_4_loan == 0].churn.value_counts())\n",
    "print(ds[ds.waiting_4_loan == 1].churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[ds.cancelled_loan == 0].churn.value_counts())\n",
    "print(ds[ds.cancelled_loan == 1].churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[ds.received_loan == 0].churn.value_counts())\n",
    "print(ds[ds.received_loan == 1].churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[ds.rejected_loan == 0].churn.value_counts())\n",
    "print(ds[ds.rejected_loan == 1].churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[ds.left_for_one_month == 0].churn.value_counts())\n",
    "print(ds[ds.left_for_one_month == 1].churn.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:** We have not observed any column that has a high bias/disproportion of 0's or 1's per any binary. We therefore conclude there is no strong bias in the dataset and we can move onto the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example observations/interpretations\n",
    "\n",
    "# The younger you are, the more likely you are to churn.\n",
    "# The less deposits, withdrawals, purchases partners and purchases the more likely to churn.\n",
    "# The more cc_taken (credit cards taken), the more likely to churn. Perhaps users dislike the credit card services.\n",
    "# The more recommendations we give to users, the less likely they are to churn.\n",
    "\n",
    "\n",
    "ds.drop(columns = ['churn', 'user','housing','payment_type','zodiac_sign']).corrwith(ds.churn).plot.bar(\n",
    "        figsize = (20,10), title = 'Correlation with Churn', fontsize = 15, rot = 90, grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of independent variables\n",
    "\n",
    "sns.set(style = 'white', font_scale = 1.1) # Builds the background\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = ds.drop(columns = ['user','churn']).corr() #Â Creating a 2D array of each correlation feature to each other\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True # This creates a the lower diagonal of the matrix as it is symmetrical\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, axes = plt.subplots(figsize = (9,9)) # Size of the plot\n",
    "fig.suptitle(\"Correlation Matrix\", fontsize = 40) # Title\n",
    "\n",
    "# Generate a custom diverging colourmap\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap = True) # Colouring\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "\n",
    "sns.heatmap(corr, mask = mask, cmap = cmap, vmax = 0.4, center = 0, \n",
    "            square = True, linewidth = 0.5, cbar_kws = {'shrink': 0.5})\n",
    "\n",
    "# We observe a strong negative correlation between Android and iOS users which is understandable\n",
    "# as, if you are an Android user you will not use iOS and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a senior analyst, we have received a useful tip that the app_web_user variable\n",
    "# is actually a function of web_user and app_downloaded. Therefore these variables are\n",
    "# no longer independent. We will therefore remove the app_web_user column from the dataset\n",
    "# and save it as a new csv file.\n",
    "\n",
    "ds = ds.drop(columns = 'app_web_user')\n",
    "ds = ds.to_csv('new_churn_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** One of the main reasons why we wish to build a model with the least or optimal amount of variables is that, as a data analyst we should understand the data well. If we have many variables, we will be expected to know the significance of each variable and its ability to impact other variables and the responding variable. Although the correlation plot and the correlation matrix may indicate this, it does not explicitly tell us these in depth details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('new_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_identifier = ds.user\n",
    "ds = ds.drop(columns = 'user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking care of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.housing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.get_dummies(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding the dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.drop(columns = ['housing_na', 'zodiac_sign_na', 'payment_type_na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds.drop(columns = 'churn'), ds.churn, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below we observe that the training dataset response variable contains around 60% 0's and 40% 1's. If we are building a model and the model predicts all values to be 0, the accuracy will be deemed 60% but it will be misleading. We will therefore need to balance the 0's and 1's in the response variable. If we have 50% 0's and 50% 1's, any additional accuracy the model produces will be seen as a result of the model being good, as opposed to a permutation of the results from the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = y_train[y_train == 1].index\n",
    "neg_index = y_train[y_train == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below sets which is the higher list and which is the lower list.\n",
    "\n",
    "if len(pos_index) > len(neg_index):\n",
    "    higher = pos_index\n",
    "    lower = neg_index\n",
    "else:\n",
    "    lower = pos_index\n",
    "    higher = neg_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes the higher and lower list the same size by randomly selecting the \n",
    "# same number of items from the higher list as there are in the lower list.\n",
    "\n",
    "higher = np.random.choice(higher, size = len(lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make higher and lower list the same type for consistency.\n",
    "\n",
    "lower = np.asarray(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_indexes = np.concatenate((lower,higher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[new_indexes, ]\n",
    "y_train = y_train.loc[new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The Standard Scaler returns a numpy array of multiple dimensions. The problem with this process is that it loses the column names and index. The index is how we identify each set of fields to the user, and we would like the column names to be build within our model. We therefore save the scaled part into a different data frame by converting the result of the Standard Scaler into its data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Logistic Regression to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Confusion Matrix and K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function of precision_score and recall_score, and it balances\n",
    "# them out.\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (True Positives)/(True Positives + False Positives)\n",
    "# Of all the positives predicted, how many of them are correct.\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (True Positives)/(True Positives + False Negatives)\n",
    "# Of all the positives that truly exist, how many did we predict as true.\n",
    "\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cvs = cross_val_score(estimator = lr, X = X_train, y = y_train, cv = 10)\n",
    "accuracy_mean = cvs.mean()\n",
    "accuracy_std = cvs.std()\n",
    "print(cvs)\n",
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_train.columns, columns = ['Features']),\n",
    "           pd.DataFrame(np.transpose(lr.coef_), columns = ['Coef'])],\n",
    "           axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With less features and the same accuracy, the model will be lighter and faster to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator = lr, n_features_to_select = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarising the selection of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Logistic Regression to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train[X_train.columns[rfe.support_]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "\n",
    "y_pred = lr.predict(X_test[X_test.columns[rfe.support_]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Confusion Matrix and K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function of precision_score and recall_score, and it balances\n",
    "# them out.\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (True Positives)/(True Positives + False Positives)\n",
    "# Of all the positives predicted, how many of them are correct.\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (True Positives)/(True Positives + False Negatives)\n",
    "# Of all the positives that truly exist, how many did we predict as true.\n",
    "\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_train.columns[rfe.support_], columns = ['Features']),\n",
    "           pd.DataFrame(np.transpose(lr.coef_), columns = ['Coef'])],\n",
    "           axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([y_test, user_identifier], axis = 1).dropna()\n",
    "results['predicted_churn'] = y_pred\n",
    "results = results[['user','churn','predicted_churn']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
